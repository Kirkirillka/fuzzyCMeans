apache.spark.master="local[*]"
apache.spark.use_config_on_hdfs=false
apache.spark.save_on_hdfs=true
apache.spark.hadoop {
    address="hdfs://localhost:9000"
    conf_path="application.conf"
    save_path="/data"
}


apache.spark.kafka {
  bootstrap_servers="localhost:9092"
  outTopics="outTest"
  inTopics="inTest"
}

apache.spark.jdbc {
  server = "localhost:5432"
  dbtable = "postgres"
  user = "postgres"
  password = "postgres"
}

streaming {

  cluster_algorithm=dfuzzystream
  datasource=ground_truth_stream
  use_history=true
  option_db_prefix = "test_with_history_270620"

  train_test {
    train=uncertain_stream
    test=ground_truth_stream
  }


  algorithm {
    # For FCM and SFCM
    k_required=5
    # For dFuzzyStream and UMicro
    k_max=5
    k_min=5
    max_iterations=1000
    m=2.0
    history=3
  }

  synthetic {
    dim=2
    window=30
    step=20

    combined {}

    gaussian {
      mu=0.0
      sigma=1.0
      limit=1000
    }

    parallel_lines {
      n=3
      x_limit=100
    }

    circles {
      n=3
      multiplication=20
    }

    uncertain_stream {
      ground_stream_name=combined
      mu = 2.0
      std = 5.0
    }

    ground_truth_stream {
      ground_stream_name=combined
      mu = 0.0
      std = 1.0
    }


  }
}